{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'clpsych'\n",
    "project_path = Path(os.getcwd()).parent\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    data_path = 'D:\\Dataset\\{0}\\dataset'.format(project_name)\n",
    "elif sys.platform == 'darwin':\n",
    "    data_path = '/Volumes/Dataset/{0}/dataset'.format(project_name)\n",
    "else:\n",
    "    data_path = Path(project_path, 'dataset')\n",
    "\n",
    "utils_path = str(Path(project_path, 'utils'))\n",
    "# including the project folder and the utils folder\n",
    "if utils_path not in ''.join(sys.path):\n",
    "    sys.path.extend([str(project_path), utils_path])\n",
    "\n",
    "print('project path = {0}'.format(project_path))\n",
    "print('data path = {0}'.format(data_path))\n",
    "print('')\n",
    "print('sys.path = {0}'.format(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in task_B_train csv file\n",
    "filename = 'clpsych19_public_task_B_train_posts.csv'\n",
    "task_b_train = pd.read_csv(Path(data_path, filename), header=None, names=['post_id', 'user_id', 'subreddits'])\n",
    "print(task_b_train.shape)\n",
    "task_b_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in crowd_train csv file\n",
    "filename = 'clpsych19_public_crowd_train.csv'\n",
    "crowd_train = pd.read_csv(Path(data_path, filename), header=None, names=['user_id', 'risk_label'])\n",
    "print(crowd_train.shape)\n",
    "crowd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shared_task_posts csv file\n",
    "filename = 'clpsych19_public_shared_task_posts.csv'\n",
    "shared_task_posts = pd.read_csv(Path(data_path, filename), header=None, \n",
    "                                names=['post_id', 'user_id', 'timestamp', 'subreddits', 'post_title', 'post_body'])\n",
    "print(shared_task_posts.shape)\n",
    "shared_task_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataset based on the mergure of the different files\n",
    "dataset = task_b_train.copy()\n",
    "dataset = dataset.merge(right=crowd_train, on='user_id', how='inner')\n",
    "dataset = dataset.merge(right=shared_task_posts, on=['user_id', 'post_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task_b_train.keys())\n",
    "print(crowd_train.keys())\n",
    "print(shared_task_posts.keys())\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dataset = dataset[['post_id','user_id','risk_label']].copy()\n",
    "n_dataset.to_csv(Path(data_path, 'post_user_risk.csv'), index=False)\n",
    "print('dataset store in {0}'.format('post_user_risk.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.now()\n",
    "filename = 'dataset_{0}.csv'.format(datetime.now().strftime('%Y%m%d%H%M%S'))\n",
    "dataset.to_csv(Path(data_path, filename), index=False)\n",
    "print('dataset store in {0}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = dataset[['risk_label']].copy()\n",
    "n_data['title_body'] = dataset['post_title'].astype(str) + dataset['post_body'].astype(str)\n",
    "n_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data.to_csv(Path(data_path, 'risk_title_body.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
