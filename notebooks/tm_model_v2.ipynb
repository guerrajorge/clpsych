{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling v2\n",
    "https://github.com/shaoxiongji/sw-detection/blob/master/clf.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project path = /home/guerramarj/github/clpsych\n",
      "data path = /home/guerramarj/github/clpsych/dataset\n",
      "model path = /home/guerramarj/github/clpsych/models\n",
      "sys.path = ['/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/vsc_install-0.11.3-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/vsc_base-2.8.3-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_framework-3.8.1-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_easyblocks-3.8.1-py2.7.egg', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages/easybuild_easyconfigs-3.8.1-py2.7.egg', '', '/cm/shared/easybuild/software/EasyBuild/3.8.1/lib/python2.7/site-packages', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python36.zip', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python3.6', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python3.6/lib-dynload', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python3.6/site-packages', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg', '/home/guerramarj/packages/anaconda3/envs/deeplearning/lib/python3.6/site-packages/IPython/extensions', '/home/guerramarj/.ipython', '/home/guerramarj/github/clpsych', '/home/guerramarj/github/clpsych/utils', '/home/guerramarj/github/clpsych/src']\n"
     ]
    }
   ],
   "source": [
    "project_name = 'clpsych'\n",
    "project_path = Path(os.getcwd()).parent\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    data_path = 'D:\\Dataset\\{0}\\dataset'.format(project_name)\n",
    "    model_path = 'D:\\Dataset\\{0}\\models'.format(project_name)\n",
    "    src_path = '/Volumes/Dataset/{0}/src'.format(project_name)\n",
    "    \n",
    "elif sys.platform == 'darwin':\n",
    "    data_path = '/Volumes/Dataset/{0}/dataset'.format(project_name)\n",
    "    model_path = '/Volumes/Dataset/{0}/models'.format(project_name)\n",
    "    src_path = '/Volumes/Dataset/{0}/src'.format(project_name)\n",
    "    \n",
    "else:\n",
    "    data_path = Path(project_path, 'dataset')\n",
    "    model_path = Path(project_path, 'models')\n",
    "    src_path = Path(project_path, 'src')\n",
    "\n",
    "utils_path = str(Path(project_path, 'utils'))\n",
    "# including the project folder and the utils folder\n",
    "if utils_path not in ''.join(sys.path):\n",
    "    sys.path.extend([str(project_path), utils_path, str(src_path)])\n",
    "\n",
    "print('project path = {0}'.format(project_path))\n",
    "print('data path = {0}'.format(data_path))\n",
    "print('model path = {0}'.format(model_path))\n",
    "print('sys.path = {0}'.format(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, utils, models, similarities\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57015, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_label</th>\n",
       "      <th>title_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>My first spoken word gig, contains rhythmic Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>My first spoken word gig. Warning: contains rh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>Me, the boy who first showed me what love was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>Being Proud @ NYC Pride 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>I wish this guy had been at my high school...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  risk_label                                         title_body\n",
       "0          a  My first spoken word gig, contains rhythmic Co...\n",
       "1          a  My first spoken word gig. Warning: contains rh...\n",
       "2          a  Me, the boy who first showed me what love was ...\n",
       "3          a                       Being Proud @ NYC Pride 2010\n",
       "4          a      I wish this guy had been at my high school..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(Path(data_path, 'risk_title_body.csv'))\n",
    "print(data.shape)\n",
    "data.columns = ['index', 'risk_label', 'title_body']\n",
    "data.drop(['index'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(article):\n",
    "    punctuation = set(string.punctuation)\n",
    "    lemmatize = WordNetLemmatizer()\n",
    "    one = \" \".join([i for i in article.lower().split() if i not in stopwords])\n",
    "    two = \"\".join(i for i in one if i not in punctuation)\n",
    "    three = \" \".join(lemmatize.lemmatize(i) for i in two.lower().split())\n",
    "    return three\n",
    "\n",
    "def pred_new(doc):\n",
    "    one = cleaning(doc).split()\n",
    "    two = dictionary.doc2bow(one)\n",
    "    return two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Topics features ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Topics features ...\")\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "text = data['title_body'].map(cleaning)\n",
    "text_list = list()\n",
    "for t in text:\n",
    "    temp = t.split()\n",
    "    text_list.append([i for i in temp if i not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num = 10\n",
    "dictionary = corpora.Dictionary(text_list)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in text_list]\n",
    "ldamodel = LdaModel(doc_term_matrix, num_topics=topic_num, id2word = dictionary, passes=50)\n",
    "\n",
    "\n",
    "probs = list()  # list of probability vectors\n",
    "for t in text:\n",
    "    prob = ldamodel[(pred_new(t))]\n",
    "    d = dict(prob)\n",
    "    for i in range(topic_num):\n",
    "        if i not in d.keys():\n",
    "            d[i] = 0\n",
    "    temp = list()\n",
    "    for i in range(topic_num):\n",
    "        temp.append(d[i])\n",
    "    probs.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('person', 0.15955004),\n",
       "   ('x', 0.035192695),\n",
       "   ('2', 0.033360675),\n",
       "   ('2url', 0.021206006),\n",
       "   ('war', 0.015685301),\n",
       "   ('3', 0.014806676),\n",
       "   ('url', 0.009923845),\n",
       "   ('bundleurl', 0.0094824005),\n",
       "   ('star', 0.008823557),\n",
       "   ('4', 0.008043063),\n",
       "   ('old', 0.007956527),\n",
       "   ('complete', 0.007714178),\n",
       "   ('v', 0.0063779927),\n",
       "   ('iiurl', 0.006050917),\n",
       "   ('age', 0.0058938884),\n",
       "   ('natural', 0.005420352),\n",
       "   ('amp', 0.0052721673),\n",
       "   ('tradestarterurl', 0.0046963873),\n",
       "   ('starveurl', 0.004335181),\n",
       "   ('empire', 0.0043012802)]),\n",
       " (1,\n",
       "  [('arkham', 0.014341211),\n",
       "   ('cat', 0.0074716066),\n",
       "   ('la', 0.0063172407),\n",
       "   ('packurl', 0.006292345),\n",
       "   ('sniper', 0.006062058),\n",
       "   ('hair', 0.005111568),\n",
       "   ('collection', 0.005023238),\n",
       "   ('seed', 0.0050196676),\n",
       "   ('elite', 0.005018717),\n",
       "   ('priority', 0.0048585394),\n",
       "   ('terrarium', 0.004815473),\n",
       "   ('skin', 0.0046895095),\n",
       "   ('water', 0.0045282613),\n",
       "   ('unity', 0.0045107105),\n",
       "   ('color', 0.004242176),\n",
       "   ('oxycodone', 0.0041780113),\n",
       "   ('sample', 0.004026056),\n",
       "   ('youtube', 0.003963503),\n",
       "   ('800', 0.0039156247),\n",
       "   ('box', 0.0037748949)]),\n",
       " (2,\n",
       "  [('w', 0.020758541),\n",
       "   ('h', 0.019146163),\n",
       "   ('key', 0.01714903),\n",
       "   ('offer', 0.012257315),\n",
       "   ('2', 0.011024141),\n",
       "   ('portal', 0.008916086),\n",
       "   ('light', 0.008098311),\n",
       "   ('borderland', 0.007817372),\n",
       "   ('iron', 0.0069434308),\n",
       "   ('king', 0.0068924613),\n",
       "   ('call', 0.0067648883),\n",
       "   ('flight', 0.006618779),\n",
       "   ('4', 0.0056088343),\n",
       "   ('torchlight', 0.0042780456),\n",
       "   ('csgo', 0.004017112),\n",
       "   ('political', 0.004006387),\n",
       "   ('red', 0.003945383),\n",
       "   ('3', 0.003580456),\n",
       "   ('goty', 0.003565278),\n",
       "   ('live', 0.003560081)]),\n",
       " (3,\n",
       "  [('steam', 0.009817346),\n",
       "   ('weekly', 0.009148164),\n",
       "   ('batman', 0.008812493),\n",
       "   ('android', 0.0072831647),\n",
       "   ('mobile', 0.0071363477),\n",
       "   ('company', 0.006917931),\n",
       "   ('mod', 0.006242319),\n",
       "   ('account', 0.0056146267),\n",
       "   ('code', 0.0055399784),\n",
       "   ('one', 0.0050061406),\n",
       "   ('monaco', 0.0049320166),\n",
       "   ('selection', 0.004930434),\n",
       "   ('asylum', 0.0048844293),\n",
       "   ('order', 0.004864909),\n",
       "   ('number', 0.0047884914),\n",
       "   ('message', 0.0047729104),\n",
       "   ('server', 0.0047408952),\n",
       "   ('site', 0.0046910457),\n",
       "   ('copy', 0.0046742395),\n",
       "   ('offer', 0.0045046294)]),\n",
       " (4,\n",
       "  [('game', 0.041954413),\n",
       "   ('person', 0.04176618),\n",
       "   ('editionurl', 0.017549876),\n",
       "   ('play', 0.01242374),\n",
       "   ('player', 0.009933908),\n",
       "   ('team', 0.0073861),\n",
       "   ('2', 0.0073543023),\n",
       "   ('playing', 0.0072537106),\n",
       "   ('time', 0.00560753),\n",
       "   ('dragon', 0.0055990266),\n",
       "   ('get', 0.0050446815),\n",
       "   ('3', 0.0049449666),\n",
       "   ('one', 0.004928626),\n",
       "   ('ultimate', 0.0047597047),\n",
       "   ('gold', 0.004750199),\n",
       "   ('dark', 0.0044296538),\n",
       "   ('level', 0.0044131866),\n",
       "   ('anno', 0.0042094532),\n",
       "   ('many', 0.00419606),\n",
       "   ('first', 0.0041052597)]),\n",
       " (5,\n",
       "  [('im', 0.01945624),\n",
       "   ('like', 0.011836207),\n",
       "   ('get', 0.011334175),\n",
       "   ('time', 0.010096623),\n",
       "   ('know', 0.008925819),\n",
       "   ('want', 0.008398397),\n",
       "   ('humble', 0.008347916),\n",
       "   ('would', 0.007383644),\n",
       "   ('one', 0.0071454486),\n",
       "   ('year', 0.0070470152),\n",
       "   ('day', 0.006848926),\n",
       "   ('feel', 0.006784291),\n",
       "   ('ive', 0.006761948),\n",
       "   ('really', 0.006684022),\n",
       "   ('go', 0.0065942015),\n",
       "   ('thing', 0.0057909805),\n",
       "   ('people', 0.0055003255),\n",
       "   ('back', 0.0053916005),\n",
       "   ('even', 0.0053314106),\n",
       "   ('going', 0.005203096)]),\n",
       " (6,\n",
       "  [('knight', 0.016010182),\n",
       "   ('ai', 0.014965667),\n",
       "   ('love', 0.010230386),\n",
       "   ('collectionurl', 0.00946283),\n",
       "   ('dog', 0.009133251),\n",
       "   ('g', 0.006076718),\n",
       "   ('poker', 0.0059618237),\n",
       "   ('man', 0.005705971),\n",
       "   ('god', 0.00520579),\n",
       "   ('old', 0.0049389526),\n",
       "   ('song', 0.004732472),\n",
       "   ('picture', 0.004597401),\n",
       "   ('big', 0.0045837965),\n",
       "   ('girl', 0.004487981),\n",
       "   ('testament', 0.0044256914),\n",
       "   ('nazi', 0.0044165393),\n",
       "   ('sherlock', 0.004317919),\n",
       "   ('animal', 0.00393881),\n",
       "   ('little', 0.003769171),\n",
       "   ('official', 0.0035827511)]),\n",
       " (7,\n",
       "  [('would', 0.016663298),\n",
       "   ('like', 0.016592795),\n",
       "   ('person', 0.013706403),\n",
       "   ('know', 0.009794432),\n",
       "   ('one', 0.009613578),\n",
       "   ('looking', 0.0080985725),\n",
       "   ('people', 0.007799761),\n",
       "   ('anyone', 0.0076958616),\n",
       "   ('make', 0.007530804),\n",
       "   ('im', 0.007475786),\n",
       "   ('think', 0.007447548),\n",
       "   ('help', 0.0073913303),\n",
       "   ('guy', 0.0070864237),\n",
       "   ('good', 0.0069982274),\n",
       "   ('post', 0.006779052),\n",
       "   ('new', 0.0064754477),\n",
       "   ('want', 0.006242295),\n",
       "   ('find', 0.005977428),\n",
       "   ('reddit', 0.0058471616),\n",
       "   ('really', 0.0056382366)]),\n",
       " (8,\n",
       "  [('bundle', 0.055377334),\n",
       "   ('u', 0.008297433),\n",
       "   ('max', 0.0071983724),\n",
       "   ('english', 0.006984489),\n",
       "   ('language', 0.0067430874),\n",
       "   ('american', 0.005428716),\n",
       "   ('state', 0.0050033266),\n",
       "   ('origin', 0.0048757945),\n",
       "   ('canada', 0.0043652323),\n",
       "   ('solar', 0.0039947378),\n",
       "   ('survey', 0.003925521),\n",
       "   ('ft', 0.0039005105),\n",
       "   ('til', 0.0038503439),\n",
       "   ('native', 0.0035069208),\n",
       "   ('country', 0.0031155325),\n",
       "   ('jumbo', 0.0030685894),\n",
       "   ('female', 0.0030669684),\n",
       "   ('russian', 0.00305535),\n",
       "   ('human', 0.0029723933),\n",
       "   ('starboundurl', 0.0029696508)]),\n",
       " (9,\n",
       "  [('person', 0.016939685),\n",
       "   ('looking', 0.0103971865),\n",
       "   ('new', 0.010246257),\n",
       "   ('card', 0.007487772),\n",
       "   ('price', 0.006719115),\n",
       "   ('game', 0.0065788245),\n",
       "   ('pc', 0.006115172),\n",
       "   ('paypal', 0.0060754777),\n",
       "   ('2', 0.005947948),\n",
       "   ('buy', 0.0055579003),\n",
       "   ('amazon', 0.005463149),\n",
       "   ('retail', 0.0052372953),\n",
       "   ('x', 0.0050319415),\n",
       "   ('listing', 0.0048998217),\n",
       "   ('build', 0.00466307),\n",
       "   ('tf2', 0.0043110703),\n",
       "   ('power', 0.0042406353),\n",
       "   ('gt', 0.0041277376),\n",
       "   ('steam', 0.004038406),\n",
       "   ('window', 0.0038080083)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ldamodel.show_topics(num_topics=num_topics,formatted=False,num_words=20)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence = ldamodel.top_topics(doc_term_matrix,dictionary=dictionary,topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3a1d45fe9de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtopic2csb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#avg coherence scores for each topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mws\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# create a unique set of keywords for each topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "topic2topkeywords = {}\n",
    "topic2csb = {}\n",
    "topic2keywords = {}\n",
    "topic2csa = {}\n",
    "num_topics =ldamodel.num_topics\n",
    "cnt =1\n",
    "for ws in coherence:\n",
    "    wset = set(w[1] for w in ws[0])\n",
    "    topic2topkeywords[cnt] = wset # set with top keywords for topic\n",
    "    topic2csb[cnt] = ws[1] #avg coherence scores for each topic\n",
    "    cnt +=1\n",
    "for ws in topics:\n",
    "    # create a unique set of keywords for each topic\n",
    "    wset = set(w[0]for w in ws[1])\n",
    "    topic2keywords[ws[0]+1] = wset\n",
    "    \n",
    "for i in range(1,num_topics+1):\n",
    "    for j in range(1,num_topics+1):  \n",
    "        if topic2keywords[i].intersection(topic2topkeywords[j])==topic2keywords[i]:\n",
    "            topic2csa[i] = topic2csb[j]\n",
    "finalData = pd.DataFrame([],columns=['Topic','words'])\n",
    "finalData['Topic']=topic2keywords.keys()\n",
    "finalData['Topic'] = finalData['Topic'].apply(lambda x: 'Topic'+str(x))\n",
    "finalData['words']=topic2keywords.values()\n",
    "finalData['cs'] = topic2csa.values()\n",
    "finalData.sort_values(by='cs',ascending=False,inplace=True)\n",
    "finalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
