{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subreddit Download Notebook\n",
    "\n",
    "This notebook contains code to download subreddits from http://files.pushshift.io/reddit/subreddits/\n",
    "\n",
    "After dowloading the files in order to decrompress the zst file:  \n",
    "\n",
    "git clone https://github.com/facebook/zstd.git  \n",
    "make  \n",
    "zstd -xvf Reddit_Subreddits.ndjson.zst  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ndjson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'clpsych'\n",
    "project_path = Path(os.getcwd()).parent\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    data_path = 'D:\\Dataset\\{0}\\dataset'.format(project_name)\n",
    "elif sys.platform == 'darwin':\n",
    "    data_path = '/Volumes/Dataset/{0}/dataset'.format(project_name)\n",
    "else:\n",
    "    data_path = Path(project_path, 'dataset')\n",
    "\n",
    "utils_path = str(Path(project_path, 'utils'))\n",
    "# including the project folder and the utils folder\n",
    "if utils_path not in ''.join(sys.path):\n",
    "    sys.path.extend([str(project_path), utils_path])\n",
    "\n",
    "print('project path = {0}'.format(project_path))\n",
    "print('data path = {0}'.format(data_path))\n",
    "print('')\n",
    "print('sys.path = {0}'.format(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = pd.read_csv(Path(data_path, 'subreddits_basic.csv')) \n",
    "basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_object = Path(data_path, 'Reddit_Subreddits.ndjson').open().read()\n",
    "data = ndjson.loads(file_object)\n",
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(data_path, '69M_reddit_accounts.csv')) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(Path(data_path, 'RC_2005-12'), lines=True) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other lists\n",
    "dir_list = ['submissions', 'submissions/daily', 'submissions/xz', 'staging','comments', 'comments/daily', 'comments/xz', 'subreddits']\n",
    "for name in dir_list:\n",
    "    \n",
    "    print('processing name = {0}'.format(name))\n",
    "    \n",
    "    url = 'http://files.pushshift.io/reddit/{0}/'.format(name)\n",
    "\n",
    "    new_datapath = Path(data_path, name)\n",
    "    \n",
    "    file_list = os.listdir(Path(new_datapath))\n",
    "    \n",
    "    page = request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    for element in soup.find_all('td'):\n",
    "\n",
    "        file_name = element.a['href'].replace('./', '')\n",
    "\n",
    "        if file_name not in file_list and '.txt' not in file_name and '.json' not in file_name:\n",
    "            print('processing file name = {0}'.format(file_name))\n",
    "\n",
    "            link_address = url + file_name\n",
    "            download_filepath = Path(new_datapath, file_name)\n",
    "            request.urlretrieve(link_address, download_filepath)  \n",
    "            print('\\t store directory = {0}'.format(download_filepath))\n",
    "            \n",
    "            file_list.append(file_name)\n",
    "            \n",
    "            print('\\t saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
